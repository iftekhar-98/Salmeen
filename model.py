"""
ML Model and Safety Scoring Logic for Salmeen Platform
Calculates safety scores and predicts driver risk levels
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import warnings

warnings.filterwarnings("ignore")


class SafetyScoreCalculator:
    """Calculate driver safety score based on driving behavior"""
    
    def __init__(self):
        self.base_score = 100
        
    def calculate_score(self, driver_data):
        """
        Calculate safety score for a driver based on their driving logs
        
        Args:
            driver_data (pd.DataFrame): DataFrame with driver's driving logs
            
        Returns:
            float: Safety score (0-100)
        """
        score = self.base_score
        
        if len(driver_data) == 0:
            return score
        
        # Penalty for speeding
        speeding_violations = driver_data[driver_data["speed_kmh"] > driver_data["speed_limit"]]
        if len(speeding_violations) > 0:
            avg_over_limit = (speeding_violations["speed_kmh"] - speeding_violations["speed_limit"]).mean()
            speeding_penalty = min(30, (len(speeding_violations) / len(driver_data)) * 40 + avg_over_limit * 0.2)
            score -= speeding_penalty
        
        # Penalty for harsh braking
        harsh_braking_count = driver_data["harsh_braking"].sum()
        harsh_braking_rate = harsh_braking_count / len(driver_data)
        harsh_braking_penalty = min(20, harsh_braking_rate * 50)
        score -= harsh_braking_penalty
        
        # Penalty for phone usage
        phone_usage_count = driver_data["phone_usage"].sum()
        phone_usage_rate = phone_usage_count / len(driver_data)
        phone_usage_penalty = min(25, phone_usage_rate * 60)
        score -= phone_usage_penalty
        
        # Penalty for violations
        violations = driver_data[driver_data["violation_type"] != "Ù„Ø§ ÙŠÙˆØ¬Ø¯"]
        violation_penalty = min(25, (len(violations) / len(driver_data)) * 50)
        score -= violation_penalty
        
        # Ensure score is between 0 and 100
        score = max(0, min(100, score))
        
        return round(score, 1)
    
    def get_score_category(self, score):
        """
        Get category label for a safety score
        
        Args:
            score (float): Safety score
            
        Returns:
            str: Category in Arabic
        """
        if score >= 85:
            return "Ù…Ù…ØªØ§Ø²"
        elif score >= 70:
            return "Ø¬ÙŠØ¯"
        elif score >= 50:
            return "Ù…ØªÙˆØ³Ø·"
        else:
            return "Ø¶Ø¹ÙŠÙ"
    
    def get_score_color(self, score):
        """
        Get color for a safety score
        
        Args:
            score (float): Safety score
            
        Returns:
            str: Color code
        """
        if score >= 85:
            return "#00C851"  # Green
        elif score >= 70:
            return "#ffbb33"  # Amber
        elif score >= 50:
            return "#ff8800"  # Orange
        else:
            return "#ff4444"  # Red


class RiskPredictor:
    """Predict driver risk level using ML"""
    
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
        self.scaler = StandardScaler()
        self.is_trained = False
        
    def prepare_features(self, df):
        """
        Prepare features for ML model
        
        Args:
            df (pd.DataFrame): Raw driving data
            
        Returns:
            dict: Feature dictionary
        """
        features = {
            "avg_speed": df["speed_kmh"].mean(),
            "max_speed": df["speed_kmh"].max(),
            "speed_violations_rate": (df["speed_kmh"] > df["speed_limit"]).sum() / len(df),
            "harsh_braking_rate": df["harsh_braking"].sum() / len(df),
            "phone_usage_rate": df["phone_usage"].sum() / len(df),
            "violation_rate": (df["violation_type"] != "Ù„Ø§ ÙŠÙˆØ¬Ø¯").sum() / len(df),
            "avg_over_limit": (df["speed_kmh"] - df["speed_limit"]).mean()
        }
        
        return features
    
    def train(self, df):
        """
        Train the risk prediction model
        
        Args:
            df (pd.DataFrame): Training data with driver_profile column
        """
        # Group by driver profile and create features
        X_list = []
        y_list = []
        
        # Create synthetic driver groups for training
        for profile in df["driver_profile"].unique():
            profile_data = df[df["driver_profile"] == profile]
            
            # Split into chunks to simulate different drivers
            chunk_size = 20
            for i in range(0, len(profile_data), chunk_size):
                chunk = profile_data.iloc[i:i+chunk_size]
                if len(chunk) >= 10:  # Minimum records
                    features = self.prepare_features(chunk)
                    X_list.append(features)
                    y_list.append(1 if profile == "risky" else 0)
        
        X = pd.DataFrame(X_list)
        y = np.array(y_list)
        
        # Train model
        if len(X) > 10:
            X_scaled = self.scaler.fit_transform(X)
            self.model.fit(X_scaled, y)
            self.is_trained = True
            print(f"âœ… Model trained on {len(X)} samples")
        else:
            print("âš ï¸ Not enough data to train model")
    
    def predict(self, driver_data):
        """
        Predict risk level for a driver
        
        Args:
            driver_data (pd.DataFrame): Driver's driving logs
            
        Returns:
            dict: Prediction result with risk level and confidence
        """
        if not self.is_trained or len(driver_data) < 10:
            return {
                "risk_level": "ØºÙŠØ± Ù…Ø­Ø¯Ø¯",
                "risk_level_en": "Unknown",
                "confidence": 0.0,
                "is_high_risk": False
            }
        
        features = self.prepare_features(driver_data)
        X = pd.DataFrame([features])
        X_scaled = self.scaler.transform(X)
        
        prediction = self.model.predict(X_scaled)[0]
        probability = self.model.predict_proba(X_scaled)[0]
        
        is_high_risk = bool(prediction == 1)
        confidence = float(probability[prediction])
        
        return {
            "risk_level": "Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø®Ø·ÙˆØ±Ø©" if is_high_risk else "Ø¢Ù…Ù†",
            "risk_level_en": "High Risk" if is_high_risk else "Safe",
            "confidence": round(confidence * 100, 1),
            "is_high_risk": is_high_risk
        }


class AICoach:
    """Generate personalized driving recommendations"""
    
    def __init__(self):
        pass
    
    def generate_recommendations(self, driver_data, safety_score):
        """
        Generate personalized recommendations based on driving behavior
        
        Args:
            driver_data (pd.DataFrame): Driver's driving logs
            safety_score (float): Current safety score
            
        Returns:
            list: List of recommendations in Arabic
        """
        recommendations = []
        
        if len(driver_data) == 0:
            return ["Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„ØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª"]
        
        # Check speeding
        speeding_violations = driver_data[driver_data["speed_kmh"] > driver_data["speed_limit"]]
        if len(speeding_violations) > 0:
            most_common_location = speeding_violations["location_name"].mode()
            if len(most_common_location) > 0:
                recommendations.append(
                    f"âš ï¸ Ù„Ø§Ø­Ø¸Ù†Ø§ ØªØ¬Ø§ÙˆØ²Ø§Ù‹ Ù…ØªÙƒØ±Ø±Ø§Ù‹ Ù„Ù„Ø³Ø±Ø¹Ø© ÙÙŠ {most_common_location.iloc[0]}. "
                    f"ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø³Ù„Ø§Ù…ØªÙƒ."
                )
        
        # Check harsh braking
        harsh_braking_rate = driver_data["harsh_braking"].sum() / len(driver_data)
        if harsh_braking_rate > 0.15:
            recommendations.append(
                "ğŸš— Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙØ±Ù…Ù„Ø© Ø§Ù„Ù…ÙØ§Ø¬Ø¦Ø© Ù…Ø±ØªÙØ¹. Ø­Ø§ÙˆÙ„ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù…Ø³Ø§ÙØ© Ø¢Ù…Ù†Ø© Ù…Ø¹ Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© "
                "ÙˆØªÙˆÙ‚Ø¹ Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø±ÙˆØ± Ù…Ø³Ø¨Ù‚Ø§Ù‹."
            )
        
        # Check phone usage
        phone_usage_rate = driver_data["phone_usage"].sum() / len(driver_data)
        if phone_usage_rate > 0.05:
            recommendations.append(
                "ğŸ“± ØªÙ… Ø±ØµØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬ÙˆØ§Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©. Ø§Ø³ØªØ®Ø¯Ù… Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ù„ÙˆØªÙˆØ« Ø£Ùˆ Ø£ÙˆÙ‚Ù Ø§Ù„Ø³ÙŠØ§Ø±Ø© "
                "ÙÙŠ Ù…ÙƒØ§Ù† Ø¢Ù…Ù† Ù„Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª."
            )
        
        # Check violations
        violations = driver_data[driver_data["violation_type"] != "Ù„Ø§ ÙŠÙˆØ¬Ø¯"]
        if len(violations) > 0:
            violation_types = violations["violation_type"].value_counts()
            most_common = violation_types.index[0]
            recommendations.append(
                f"âš¡ ØªÙ… Ø±ØµØ¯ Ù…Ø®Ø§Ù„ÙØ©: {most_common}. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø±ÙˆØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØºØ±Ø§Ù…Ø§Øª "
                f"ÙˆØ§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø³Ù„Ø§Ù…ØªÙƒ ÙˆØ³Ù„Ø§Ù…Ø© Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†."
            )
        
        # Positive reinforcement
        if safety_score >= 85:
            recommendations.append(
                "âœ… Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø²! Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ø¢Ù…Ù†Ø© ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø±ÙˆØ±."
            )
        
        # General advice if no specific issues
        if len(recommendations) == 0:
            recommendations.append(
                "âœ… Ù‚ÙŠØ§Ø¯ØªÙƒ Ø¬ÙŠØ¯Ø© Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…. Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø±ÙˆØ± ÙˆØ§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ø¢Ù…Ù†Ø©."
            )
        
        return recommendations


if __name__ == "__main__":
    # Test the model
    from utils import generate_dummy_data
    
    print("Testing Safety Score Calculator and Risk Predictor...")
    
    # Generate data
    df = generate_dummy_data(500)
    
    # Test safety score
    calculator = SafetyScoreCalculator()
    sample_driver_data = df.head(50)
    score = calculator.calculate_score(sample_driver_data)
    category = calculator.get_score_category(score)
    print(f"\nğŸ“Š Safety Score: {score}/100 ({category})")
    
    # Test risk predictor
    predictor = RiskPredictor()
    predictor.train(df)
    prediction = predictor.predict(sample_driver_data)
    print(f"ğŸ¯ Risk Prediction: {prediction['risk_level']} (Confidence: {prediction['confidence']}%)")
    
    # Test AI coach
    coach = AICoach()
    recommendations = coach.generate_recommendations(sample_driver_data, score)
    print(f"\nğŸ’¡ AI Recommendations:")
    for rec in recommendations:
        print(f"  - {rec}")
